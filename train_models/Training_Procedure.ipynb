{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Process (in Google Colab)\n",
    "\n",
    "### Environment: Google Colab (https://colab.research.google.com/)\n",
    "* Actually, our models are trained via a remote server provided by one of our group members. Due to this reason, we counld not let the output into notebook to show. However, it is possible to access the logs of the models we have trained. Training logs are shown in the following folders: /afters_dataAug and /before_dataAug.\n",
    "* For testing if our training codes and commands are runable in an eazier way, we decided to show the whole procedure in Colab.\n",
    "* We are 100% sure that these commands are runable in Google Colab. \n",
    "* So we suggest run this notebook in Colab!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. git clone our altered yolov5 repo\n",
    "* If you want to run in local machine, excute this command or copy the submitted codes to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "phlVc_pQqxNb",
    "outputId": "287fc54a-88b9-4af7-f0bc-6cfe42d9d620"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'yolov5_for_caltech'...\n",
      "remote: Enumerating objects: 14780, done.\u001b[K\n",
      "remote: Counting objects: 100% (15/15), done.\u001b[K\n",
      "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
      "remote: Total 14780 (delta 6), reused 0 (delta 0), pack-reused 14765\u001b[K\n",
      "Receiving objects: 100% (14780/14780), 13.63 MiB | 18.76 MiB/s, done.\n",
      "Resolving deltas: 100% (10195/10195), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/PinhengChen/yolov5_for_caltech.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Install required files for yolov5\n",
    "(It's fine to ignore warnings and errors below)\n",
    "* This is the command for Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "8WoRy7McW5TR",
    "outputId": "63d94e4c-bfc0-498c-baec-6005f7dc7e9e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from -r yolov5_for_caltech/requirements.txt (line 5)) (7.9.0)\n",
      "Collecting ipython\n",
      "  Downloading ipython-7.34.0-py3-none-any.whl (793 kB)\n",
      "\u001b[K     |████████████████████████████████| 793 kB 32.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.7/dist-packages (from -r yolov5_for_caltech/requirements.txt (line 6)) (3.2.2)\n",
      "Collecting matplotlib>=3.2.2\n",
      "  Downloading matplotlib-3.5.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.2 MB 76.7 MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from -r yolov5_for_caltech/requirements.txt (line 7)) (1.21.6)\n",
      "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from -r yolov5_for_caltech/requirements.txt (line 8)) (4.6.0.66)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from -r yolov5_for_caltech/requirements.txt (line 9)) (7.1.2)\n",
      "Collecting Pillow>=7.1.2\n",
      "  Downloading Pillow-9.3.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.2 MB 79.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from -r yolov5_for_caltech/requirements.txt (line 10)) (5.4.8)\n",
      "Collecting psutil\n",
      "  Downloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
      "\u001b[K     |████████████████████████████████| 280 kB 85.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.7/dist-packages (from -r yolov5_for_caltech/requirements.txt (line 11)) (6.0)\n",
      "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.7/dist-packages (from -r yolov5_for_caltech/requirements.txt (line 12)) (2.23.0)\n",
      "Collecting requests>=2.23.0\n",
      "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
      "\u001b[K     |████████████████████████████████| 62 kB 1.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from -r yolov5_for_caltech/requirements.txt (line 13)) (1.7.3)\n",
      "Collecting thop>=0.1.1\n",
      "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from -r yolov5_for_caltech/requirements.txt (line 15)) (1.12.1+cu113)\n",
      "Collecting torch>=1.7.0\n",
      "  Downloading torch-1.13.0-cp37-cp37m-manylinux1_x86_64.whl (890.2 MB)\n",
      "\u001b[K     |██████████████████████████████  | 834.1 MB 1.1 MB/s eta 0:00:50tcmalloc: large alloc 1147494400 bytes == 0x3a1f2000 @  0x7f7aecdb1615 0x58ead6 0x4f355e 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x510325 0x5b4ee6 0x58ff2e 0x50d482 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4bac0a 0x538a76 0x590ae5 0x510280 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50c4fc 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e\n",
      "\u001b[K     |████████████████████████████████| 890.2 MB 6.7 kB/s \n",
      "\u001b[?25hRequirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from -r yolov5_for_caltech/requirements.txt (line 16)) (0.13.1+cu113)\n",
      "Collecting torchvision>=0.8.1\n",
      "  Downloading torchvision-0.14.0-cp37-cp37m-manylinux1_x86_64.whl (24.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 24.3 MB 775 kB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.7/dist-packages (from -r yolov5_for_caltech/requirements.txt (line 17)) (4.64.1)\n",
      "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from -r yolov5_for_caltech/requirements.txt (line 21)) (2.9.1)\n",
      "Collecting tensorboard>=2.4.1\n",
      "  Downloading tensorboard-2.11.0-py3-none-any.whl (6.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.0 MB 77.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.7/dist-packages (from -r yolov5_for_caltech/requirements.txt (line 26)) (1.3.5)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from -r yolov5_for_caltech/requirements.txt (line 27)) (0.11.2)\n",
      "Collecting seaborn>=0.11.0\n",
      "  Downloading seaborn-0.12.1-py3-none-any.whl (288 kB)\n",
      "\u001b[K     |████████████████████████████████| 288 kB 88.4 MB/s \n",
      "\u001b[?25hCollecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
      "\u001b[K     |████████████████████████████████| 965 kB 84.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r yolov5_for_caltech/requirements.txt (line 6)) (3.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r yolov5_for_caltech/requirements.txt (line 6)) (21.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r yolov5_for_caltech/requirements.txt (line 6)) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r yolov5_for_caltech/requirements.txt (line 6)) (1.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r yolov5_for_caltech/requirements.txt (line 6)) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r yolov5_for_caltech/requirements.txt (line 12)) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r yolov5_for_caltech/requirements.txt (line 12)) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r yolov5_for_caltech/requirements.txt (line 12)) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r yolov5_for_caltech/requirements.txt (line 12)) (2.10)\n",
      "Collecting nvidia-cuda-runtime-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001b[K     |████████████████████████████████| 849 kB 83.5 MB/s \n",
      "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 21.0 MB 906 kB/s \n",
      "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 317.1 MB 34 kB/s \n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7.0->-r yolov5_for_caltech/requirements.txt (line 15)) (4.1.1)\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 557.1 MB 12 kB/s \n",
      "\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.7.0->-r yolov5_for_caltech/requirements.txt (line 15)) (0.38.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.7.0->-r yolov5_for_caltech/requirements.txt (line 15)) (57.4.0)\n",
      "Requirement already satisfied: protobuf<4,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r yolov5_for_caltech/requirements.txt (line 21)) (3.19.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r yolov5_for_caltech/requirements.txt (line 21)) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r yolov5_for_caltech/requirements.txt (line 21)) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r yolov5_for_caltech/requirements.txt (line 21)) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r yolov5_for_caltech/requirements.txt (line 21)) (1.0.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r yolov5_for_caltech/requirements.txt (line 21)) (2.14.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r yolov5_for_caltech/requirements.txt (line 21)) (1.3.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r yolov5_for_caltech/requirements.txt (line 21)) (0.4.6)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r yolov5_for_caltech/requirements.txt (line 21)) (1.50.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.4->-r yolov5_for_caltech/requirements.txt (line 26)) (2022.6)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r yolov5_for_caltech/requirements.txt (line 21)) (4.9)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r yolov5_for_caltech/requirements.txt (line 21)) (1.15.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r yolov5_for_caltech/requirements.txt (line 21)) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r yolov5_for_caltech/requirements.txt (line 21)) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r yolov5_for_caltech/requirements.txt (line 21)) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r yolov5_for_caltech/requirements.txt (line 21)) (4.13.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.4.1->-r yolov5_for_caltech/requirements.txt (line 21)) (3.10.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r yolov5_for_caltech/requirements.txt (line 21)) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r yolov5_for_caltech/requirements.txt (line 21)) (3.2.2)\n",
      "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->-r yolov5_for_caltech/requirements.txt (line 5)) (5.1.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython->-r yolov5_for_caltech/requirements.txt (line 5)) (2.0.10)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->-r yolov5_for_caltech/requirements.txt (line 5)) (2.6.1)\n",
      "Collecting matplotlib-inline\n",
      "  Downloading matplotlib_inline-0.1.6-py3-none-any.whl (9.4 kB)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->-r yolov5_for_caltech/requirements.txt (line 5)) (0.7.5)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.7/dist-packages (from ipython->-r yolov5_for_caltech/requirements.txt (line 5)) (4.8.0)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->-r yolov5_for_caltech/requirements.txt (line 5)) (4.4.2)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython->-r yolov5_for_caltech/requirements.txt (line 5)) (0.2.0)\n",
      "Collecting jedi>=0.16\n",
      "  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 79.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.16->ipython->-r yolov5_for_caltech/requirements.txt (line 5)) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect>4.3->ipython->-r yolov5_for_caltech/requirements.txt (line 5)) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->-r yolov5_for_caltech/requirements.txt (line 5)) (0.2.5)\n",
      "Installing collected packages: requests, nvidia-cublas-cu11, Pillow, nvidia-cudnn-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, fonttools, torch, matplotlib-inline, matplotlib, jedi, torchvision, thop, tensorboard, seaborn, psutil, ipython\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.23.0\n",
      "    Uninstalling requests-2.23.0:\n",
      "      Successfully uninstalled requests-2.23.0\n",
      "  Attempting uninstall: Pillow\n",
      "    Found existing installation: Pillow 7.1.2\n",
      "    Uninstalling Pillow-7.1.2:\n",
      "      Successfully uninstalled Pillow-7.1.2\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.12.1+cu113\n",
      "    Uninstalling torch-1.12.1+cu113:\n",
      "      Successfully uninstalled torch-1.12.1+cu113\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 3.2.2\n",
      "    Uninstalling matplotlib-3.2.2:\n",
      "      Successfully uninstalled matplotlib-3.2.2\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.13.1+cu113\n",
      "    Uninstalling torchvision-0.13.1+cu113:\n",
      "      Successfully uninstalled torchvision-0.13.1+cu113\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.9.1\n",
      "    Uninstalling tensorboard-2.9.1:\n",
      "      Successfully uninstalled tensorboard-2.9.1\n",
      "  Attempting uninstall: seaborn\n",
      "    Found existing installation: seaborn 0.11.2\n",
      "    Uninstalling seaborn-0.11.2:\n",
      "      Successfully uninstalled seaborn-0.11.2\n",
      "  Attempting uninstall: psutil\n",
      "    Found existing installation: psutil 5.4.8\n",
      "    Uninstalling psutil-5.4.8:\n",
      "      Successfully uninstalled psutil-5.4.8\n",
      "  Attempting uninstall: ipython\n",
      "    Found existing installation: ipython 7.9.0\n",
      "    Uninstalling ipython-7.9.0:\n",
      "      Successfully uninstalled ipython-7.9.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.13.0 which is incompatible.\n",
      "torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.13.0 which is incompatible.\n",
      "tensorflow 2.9.2 requires tensorboard<2.10,>=2.9, but you have tensorboard 2.11.0 which is incompatible.\n",
      "google-colab 1.0.0 requires ipython~=7.9.0, but you have ipython 7.34.0 which is incompatible.\u001b[0m\n",
      "Successfully installed Pillow-9.3.0 fonttools-4.38.0 ipython-7.34.0 jedi-0.18.1 matplotlib-3.5.3 matplotlib-inline-0.1.6 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 psutil-5.9.4 requests-2.28.1 seaborn-0.12.1 tensorboard-2.11.0 thop-0.1.1.post2209072238 torch-1.13.0 torchvision-0.14.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "IPython",
         "PIL",
         "matplotlib",
         "mpl_toolkits",
         "psutil"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install -U -r yolov5_for_caltech/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This is the command for local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U -r ../yolov5/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Enter the yolov5_for_caltech folder\n",
    "* This is the command for Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JUv_2Pj5coML",
    "outputId": "6bcad6ba-dd52-4a96-c210-90de289a34c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/yolov5_for_caltech\n"
     ]
    }
   ],
   "source": [
    "%cd /content/yolov5_for_caltech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This is the command for local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /yolov5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Import pytorch and check GPU information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qHsEd5G2W7mF",
    "outputId": "a4be7bd9-91e7-4b20-b7db-483388b5ce82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch 1.13.0+cu117 _CudaDeviceProperties(name='A100-SXM4-40GB', major=8, minor=0, total_memory=40536MB, multi_processor_count=108)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from IPython.display import Image  # for displaying images\n",
    "import matplotlib as plt\n",
    "#from utils.google_utils import gdrive_download  # for downloading models/datasets\n",
    "print('torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Install Roboflow for downloading our dataset\n",
    "(It's fine to ignore warnings and errors below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "UMXxAA9Nd6bF",
    "outputId": "b0f17c2d-744e-4282-bf48-3bc4ba9fb911",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting roboflow\n",
      "  Downloading roboflow-0.2.20-py3-none-any.whl (41 kB)\n",
      "\u001b[K     |████████████████████████████████| 41 kB 699 kB/s \n",
      "\u001b[?25hCollecting python-dotenv\n",
      "  Downloading python_dotenv-0.21.0-py3-none-any.whl (18 kB)\n",
      "Collecting urllib3==1.26.6\n",
      "  Downloading urllib3-1.26.6-py2.py3-none-any.whl (138 kB)\n",
      "\u001b[K     |████████████████████████████████| 138 kB 77.6 MB/s \n",
      "\u001b[?25hRequirement already satisfied: idna==2.10 in /usr/local/lib/python3.7/dist-packages (from roboflow) (2.10)\n",
      "Requirement already satisfied: opencv-python-headless>=4.5.1.48 in /usr/local/lib/python3.7/dist-packages (from roboflow) (4.6.0.66)\n",
      "Collecting wget\n",
      "  Downloading wget-3.2.zip (10 kB)\n",
      "Collecting cycler==0.10.0\n",
      "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from roboflow) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from roboflow) (1.21.6)\n",
      "Requirement already satisfied: glob2 in /usr/local/lib/python3.7/dist-packages (from roboflow) (0.7)\n",
      "Collecting pyparsing==2.4.7\n",
      "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
      "\u001b[K     |████████████████████████████████| 67 kB 5.3 MB/s \n",
      "\u001b[?25hCollecting certifi==2021.5.30\n",
      "  Downloading certifi-2021.5.30-py2.py3-none-any.whl (145 kB)\n",
      "\u001b[K     |████████████████████████████████| 145 kB 89.7 MB/s \n",
      "\u001b[?25hCollecting requests-toolbelt\n",
      "  Downloading requests_toolbelt-0.10.1-py2.py3-none-any.whl (54 kB)\n",
      "\u001b[K     |████████████████████████████████| 54 kB 3.6 MB/s \n",
      "\u001b[?25hCollecting chardet==4.0.0\n",
      "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
      "\u001b[K     |████████████████████████████████| 178 kB 86.6 MB/s \n",
      "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from roboflow) (1.15.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from roboflow) (3.5.3)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.7/dist-packages (from roboflow) (6.0)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from roboflow) (2.8.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from roboflow) (2.28.1)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from roboflow) (4.64.1)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from roboflow) (9.3.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.3.1->roboflow) (4.1.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib->roboflow) (4.38.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib->roboflow) (21.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests->roboflow) (2.1.1)\n",
      "Building wheels for collected packages: wget\n",
      "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9675 sha256=fca7e1502186e3c3717f4a1058642ccb5c206ac23a5d4e3bca97f39559e523dc\n",
      "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
      "Successfully built wget\n",
      "Installing collected packages: urllib3, pyparsing, certifi, cycler, wget, requests-toolbelt, python-dotenv, chardet, roboflow\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.24.3\n",
      "    Uninstalling urllib3-1.24.3:\n",
      "      Successfully uninstalled urllib3-1.24.3\n",
      "  Attempting uninstall: pyparsing\n",
      "    Found existing installation: pyparsing 3.0.9\n",
      "    Uninstalling pyparsing-3.0.9:\n",
      "      Successfully uninstalled pyparsing-3.0.9\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2022.9.24\n",
      "    Uninstalling certifi-2022.9.24:\n",
      "      Successfully uninstalled certifi-2022.9.24\n",
      "  Attempting uninstall: cycler\n",
      "    Found existing installation: cycler 0.11.0\n",
      "    Uninstalling cycler-0.11.0:\n",
      "      Successfully uninstalled cycler-0.11.0\n",
      "  Attempting uninstall: chardet\n",
      "    Found existing installation: chardet 3.0.4\n",
      "    Uninstalling chardet-3.0.4:\n",
      "      Successfully uninstalled chardet-3.0.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-colab 1.0.0 requires ipython~=7.9.0, but you have ipython 7.34.0 which is incompatible.\u001b[0m\n",
      "Successfully installed certifi-2021.5.30 chardet-4.0.0 cycler-0.10.0 pyparsing-2.4.7 python-dotenv-0.21.0 requests-toolbelt-0.10.1 roboflow-0.2.20 urllib3-1.26.6 wget-3.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "certifi",
         "cycler",
         "pyparsing"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install roboflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Import the dataset without augmentation from Roboflow\n",
    "Dataset website link: https://universe.roboflow.com/pionc/caltech-6f68o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CkZbDQmlCIej",
    "outputId": "2aa5e2fe-9b3d-4a18-e54a-7fcdd2190bd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Downloading Dataset Version Zip in caltech-4 to yolov5pytorch: 100% [94920020 / 94920020] bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Dataset Version Zip to caltech-4 in yolov5pytorch:: 100%|██████████| 3112/3112 [00:00<00:00, 5537.62it/s]\n"
     ]
    }
   ],
   "source": [
    "### download original dataset\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"NkXCXC3zILAYB21nwqZb\")\n",
    "project = rf.workspace(\"pionc\").project(\"caltech-6f68o\")\n",
    "dataset = project.version(4).download(\"yolov5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Import the dataset with Mosaic\n",
    "Dataset website link: https://universe.roboflow.com/visdronedataset/caltech-ped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_8qziblkxDRm",
    "outputId": "ab2e372f-03b7-447d-c2cd-9b9d959dedc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Downloading Dataset Version Zip in caltech-ped-2 to yolov5pytorch: 100% [134042845 / 134042845] bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Dataset Version Zip to caltech-ped-2 in yolov5pytorch:: 100%|██████████| 7440/7440 [00:01<00:00, 6796.41it/s]\n"
     ]
    }
   ],
   "source": [
    "### download mosaiced dataset\n",
    "rf = Roboflow(api_key=\"NkXCXC3zILAYB21nwqZb\")\n",
    "project = rf.workspace(\"visdronedataset\").project(\"caltech-ped\")\n",
    "dataset = project.version(2).download(\"yolov5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Connect to Google drive for saving results.\n",
    "(It's fine to ignore this section if you do not want to save the results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jhs1cUe0yq-d",
    "outputId": "fac16de1-12d4-4fb7-873b-01da52244a3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "### connect google drive for saving results in the drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Train the original yolov5l model for the dataset without augmentation.\n",
    "We stop the training manually after 1 epoch in this notebook. For more training log details, please see /before_dataAug/base_b4.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### * This is the command for colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SQ7p8e8HjPXE",
    "outputId": "f072c68f-6944-4252-d345-5e942f0d7c79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=yolov5l.yaml, data=/content/yolov5_for_caltech/caltech-4/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=350, batch_size=-1, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m⚠️ YOLOv5 is out of date by 29 commits. Use `git pull ultralytics master` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
      "YOLOv5 🚀 v6.2-240-g08889c1 Python-3.7.15 torch-1.13.0+cu117 CUDA:0 (A100-SXM4-40GB, 40536MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "2022-11-20 06:46:08.051651: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
      "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
      "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
      "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
      "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
      "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
      "  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
      " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
      " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
      " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
      " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
      " 24      [17, 20, 23]  1     32310  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n",
      "YOLOv5l summary: 368 layers, 46138294 parameters, 46138294 gradients, 108.2 GFLOPs\n",
      "\n",
      "Transferred 57/613 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for --imgsz 640\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (A100-SXM4-40GB) 39.59G total, 0.69G reserved, 0.35G allocated, 38.54G free\n",
      "      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n",
      "    46138294       108.2         1.137          75.4         26.52        (1, 3, 640, 640)                    list\n",
      "    46138294       216.5         1.609          43.9          23.8        (2, 3, 640, 640)                    list\n",
      "    46138294       432.9         2.554         40.19         24.31        (4, 3, 640, 640)                    list\n",
      "    46138294       865.8         4.551         46.36         30.64        (8, 3, 640, 640)                    list\n",
      "    46138294        1732         8.475         51.82          48.2       (16, 3, 640, 640)                    list\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 61 for CUDA:0 31.57G/39.59G (80%) ✅\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 101 weight(decay=0.0), 104 weight(decay=0.0004765625), 104 bias\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/yolov5_for_caltech/caltech-4/train/labels.cache' images and labels... 1082 found, 0 missing, 4 empty, 0 corrupt: 100% 1082/1082 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/yolov5_for_caltech/caltech-4/valid/labels.cache' images and labels... 161 found, 0 missing, 0 empty, 0 corrupt: 100% 161/161 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.61 anchors/target, 0.996 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
      "Plotting labels to runs/train/exp4/labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/train/exp4\u001b[0m\n",
      "Starting training for 350 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      0/349      34.1G     0.1202    0.02894          0        101        640: 100% 18/18 [00:12<00:00,  1.39it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0% 0/2 [00:00<?, ?it/s]WARNING ⚠️ NMS time limit 6.600s exceeded\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:09<00:00,  4.73s/it]\n",
      "                   all        161        328   8.44e-05     0.0122   4.31e-05   4.31e-06\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      1/349      40.3G     0.1171    0.02895          0        159        640:  22% 4/18 [00:02<00:07,  1.91it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 630, in <module>\n",
      "    main(opt)\n",
      "  File \"train.py\", line 524, in main\n",
      "    train(opt.hyp, opt, device, callbacks)\n",
      "  File \"train.py\", line 319, in train\n",
      "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0)  # clip gradients\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/utils/clip_grad.py\", line 56, in clip_grad_norm_\n",
      "    g.detach().mul_(clip_coef_clamped.to(g.device))\n",
      "KeyboardInterrupt\n",
      "Error in atexit._run_exitfuncs:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/tqdm/_monitor.py\", line 44, in exit\n",
      "    self.join()\n",
      "  File \"/usr/lib/python3.7/threading.py\", line 1044, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/usr/lib/python3.7/threading.py\", line 1060, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python train.py --data /content/yolov5_for_caltech/caltech-4/data.yaml --cfg yolov5l.yaml --batch-size -1 --epochs 350"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### * This is the command for local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: can't open file '/Users/chenpinheng/Documents/GitHub/9444NeuralNetworkAndDeepLearning/../yolov5/train.py': [Errno 2] No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!python ../yolov5/train.py --data caltech-4/data.yaml --cfg ../yolov5/models/yolov5l.yaml --batch-size -1 --epochs 350"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Train the yolov5l + mobilenetv3 model for the dataset without augmentation.\n",
    "We stop the training manually after 1 epoch in this notebook. For more training log details, please see /before_dataAug/mobile_b4.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### * This is the command for Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RMzybj6bTi3p",
    "outputId": "f346f2cf-57f0-40cb-bce3-69be7695bdf3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=yolov5l_mobilenetv3.yaml, data=/content/yolov5_for_caltech/caltech-4/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=350, batch_size=-1, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m⚠️ YOLOv5 is out of date by 29 commits. Use `git pull ultralytics master` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
      "YOLOv5 🚀 v6.2-240-g08889c1 Python-3.7.15 torch-1.13.0+cu117 CUDA:0 (A100-SXM4-40GB, 40536MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "2022-11-20 06:45:15.654361: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
      "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
      "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
      "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
      "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
      "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
      "  9                -1  1         3  models.common.ECA                       [1024, 1024]                  \n",
      " 10                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
      " 11                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 12                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 13           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 14                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
      " 15                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 16                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 17           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 18                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
      " 19                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 20          [-1, 15]  1         0  models.common.Concat                    [1]                           \n",
      " 21                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
      " 22                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
      " 23          [-1, 11]  1         0  models.common.Concat                    [1]                           \n",
      " 24                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
      " 25      [18, 21, 24]  1     32310  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n",
      "YOLOv5l_mobilenetv3 summary: 372 layers, 46138297 parameters, 46138297 gradients, 108.2 GFLOPs\n",
      "\n",
      "Transferred 31/614 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for --imgsz 640\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (A100-SXM4-40GB) 39.59G total, 0.69G reserved, 0.35G allocated, 38.54G free\n",
      "      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n",
      "    46138297       108.2         1.139         76.37         27.46        (1, 3, 640, 640)                    list\n",
      "    46138297       216.5         1.609         45.34         24.66        (2, 3, 640, 640)                    list\n",
      "    46138297       432.9         2.556         40.75         26.84        (4, 3, 640, 640)                    list\n",
      "    46138297       865.8         4.559         49.23         31.77        (8, 3, 640, 640)                    list\n",
      "    46138297        1732         8.491         52.58         48.48       (16, 3, 640, 640)                    list\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 61 for CUDA:0 31.64G/39.59G (80%) ✅\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 101 weight(decay=0.0), 105 weight(decay=0.0004765625), 104 bias\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/yolov5_for_caltech/caltech-4/train/labels.cache' images and labels... 1082 found, 0 missing, 4 empty, 0 corrupt: 100% 1082/1082 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/yolov5_for_caltech/caltech-4/valid/labels.cache' images and labels... 161 found, 0 missing, 0 empty, 0 corrupt: 100% 161/161 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.61 anchors/target, 0.996 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
      "Plotting labels to runs/train/exp3/labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/train/exp3\u001b[0m\n",
      "Starting training for 350 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      0/349      34.1G     0.1204    0.02935          0        101        640: 100% 18/18 [00:12<00:00,  1.46it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0% 0/2 [00:00<?, ?it/s]WARNING ⚠️ NMS time limit 6.600s exceeded\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:09<00:00,  4.71s/it]\n",
      "                   all        161        328   8.39e-05     0.0122   4.28e-05   4.28e-06\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      1/349      40.3G     0.1185    0.02894          0        142        640:  44% 8/18 [00:03<00:04,  2.13it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 630, in <module>\n",
      "    main(opt)\n",
      "  File \"train.py\", line 524, in main\n",
      "    train(opt.hyp, opt, device, callbacks)\n",
      "  File \"train.py\", line 307, in train\n",
      "    loss, loss_items = compute_loss(pred, targets.to(device))  # loss scaled by batch_size\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python train.py --data /content/yolov5_for_caltech/caltech-4/data.yaml --cfg yolov5l_mobilenetv3.yaml --batch-size -1 --epochs 350"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### * This is the command for local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ../yolov5/train.py --data caltech-4/data.yaml --cfg ../yolov5/models/yolov5l_mobilenetv3.yaml --batch-size -1 --epochs 350"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 Train the yolov5l + SE model for the dataset without augmentation.\n",
    "We stop the training manually after 1 epoch in this notebook. For more training log details, please see /before_dataAug/se_b4.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  * This is the command for Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v8oXRNBFyZfa",
    "outputId": "d99c3f20-9ffa-4867-a826-a21aeaee8912",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=yolov5l_se.yaml, data=/content/yolov5_for_caltech/caltech-4/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=350, batch_size=-1, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m⚠️ YOLOv5 is out of date by 29 commits. Use `git pull ultralytics master` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
      "YOLOv5 🚀 v6.2-240-g08889c1 Python-3.7.15 torch-1.13.0+cu117 CUDA:0 (A100-SXM4-40GB, 40536MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "2022-11-20 06:47:15.115745: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
      "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
      "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
      "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
      "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
      "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
      "  9                -1  1    131072  models.common.SE                        [1024, 1024]                  \n",
      " 10                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
      " 11                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 12                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 13           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 14                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
      " 15                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 16                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 17           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 18                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
      " 19                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 20          [-1, 15]  1         0  models.common.Concat                    [1]                           \n",
      " 21                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
      " 22                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
      " 23          [-1, 11]  1         0  models.common.Concat                    [1]                           \n",
      " 24                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
      " 25      [18, 21, 24]  1     32310  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n",
      "YOLOv5l_se summary: 374 layers, 46269366 parameters, 46269366 gradients, 108.3 GFLOPs\n",
      "\n",
      "Transferred 31/615 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for --imgsz 640\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (A100-SXM4-40GB) 39.59G total, 0.69G reserved, 0.35G allocated, 38.54G free\n",
      "      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n",
      "    46269366       108.2         1.141         75.11         27.71        (1, 3, 640, 640)                    list\n",
      "    46269366       216.5         1.611         45.26         24.77        (2, 3, 640, 640)                    list\n",
      "    46269366       432.9         2.554          39.4         27.06        (4, 3, 640, 640)                    list\n",
      "    46269366       865.8         4.557         48.56         34.25        (8, 3, 640, 640)                    list\n",
      "    46269366        1732         8.489         53.58         48.75       (16, 3, 640, 640)                    list\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 61 for CUDA:0 31.63G/39.59G (80%) ✅\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 101 weight(decay=0.0), 106 weight(decay=0.0004765625), 104 bias\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/yolov5_for_caltech/caltech-4/train/labels.cache' images and labels... 1082 found, 0 missing, 4 empty, 0 corrupt: 100% 1082/1082 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/yolov5_for_caltech/caltech-4/valid/labels.cache' images and labels... 161 found, 0 missing, 0 empty, 0 corrupt: 100% 161/161 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.61 anchors/target, 0.996 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
      "Plotting labels to runs/train/exp5/labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/train/exp5\u001b[0m\n",
      "Starting training for 350 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      0/349      34.2G      0.121     0.0303          0        101        640: 100% 18/18 [00:12<00:00,  1.43it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0% 0/2 [00:00<?, ?it/s]WARNING ⚠️ NMS time limit 6.600s exceeded\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:09<00:00,  4.72s/it]\n",
      "                   all        161        328   8.39e-05     0.0122   4.42e-05   4.42e-06\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      1/349      40.3G      0.118    0.02944          0        135        640:  28% 5/18 [00:02<00:06,  2.06it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 630, in <module>\n",
      "    main(opt)\n",
      "  File \"train.py\", line 524, in main\n",
      "    train(opt.hyp, opt, device, callbacks)\n",
      "  File \"train.py\", line 307, in train\n",
      "    loss, loss_items = compute_loss(pred, targets.to(device))  # loss scaled by batch_size\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python train.py --data /content/yolov5_for_caltech/caltech-4/data.yaml --cfg yolov5l_se.yaml --batch-size -1 --epochs 350"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### * This is the command for local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ../yolov5/train.py --data caltech-4/data.yaml --cfg ../yolov5/models/yolov5l_se.yaml --batch-size -1 --epochs 350"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4 Train the yolov5l + ECA model for the dataset without augmentation.\n",
    "We stop the training manually after 1 epoch in this notebook. For more training log details, please see /before_dataAug/eca_b4.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### * This is the command for Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vgemOwTlynxo",
    "outputId": "c3cb6cae-1afe-42c4-902f-1d64dc73920e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=yolov5l_eca.yaml, data=/content/yolov5_for_caltech/caltech-4/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=350, batch_size=-1, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m⚠️ YOLOv5 is out of date by 29 commits. Use `git pull ultralytics master` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
      "YOLOv5 🚀 v6.2-240-g08889c1 Python-3.7.15 torch-1.13.0+cu117 CUDA:0 (A100-SXM4-40GB, 40536MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "2022-11-20 06:53:47.042416: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
      "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
      "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
      "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
      "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
      "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
      "  9                -1  1         3  models.common.ECA                       [1024, 1024]                  \n",
      " 10                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
      " 11                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 12                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 13           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 14                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
      " 15                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 16                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 17           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 18                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
      " 19                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 20          [-1, 15]  1         0  models.common.Concat                    [1]                           \n",
      " 21                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
      " 22                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
      " 23          [-1, 11]  1         0  models.common.Concat                    [1]                           \n",
      " 24                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
      " 25      [18, 21, 24]  1     32310  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n",
      "YOLOv5l_eca summary: 372 layers, 46138297 parameters, 46138297 gradients, 108.2 GFLOPs\n",
      "\n",
      "Transferred 31/614 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for --imgsz 640\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (A100-SXM4-40GB) 39.59G total, 0.69G reserved, 0.35G allocated, 38.54G free\n",
      "      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n",
      "    46138297       108.2         1.139         74.95         27.79        (1, 3, 640, 640)                    list\n",
      "    46138297       216.5         1.609         42.71         23.74        (2, 3, 640, 640)                    list\n",
      "    46138297       432.9         2.556         40.89         25.12        (4, 3, 640, 640)                    list\n",
      "    46138297       865.8         4.559         47.65         30.67        (8, 3, 640, 640)                    list\n",
      "    46138297        1732         8.491         52.04         48.25       (16, 3, 640, 640)                    list\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 61 for CUDA:0 31.64G/39.59G (80%) ✅\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 101 weight(decay=0.0), 105 weight(decay=0.0004765625), 104 bias\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/yolov5_for_caltech/caltech-4/train/labels.cache' images and labels... 1082 found, 0 missing, 4 empty, 0 corrupt: 100% 1082/1082 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/yolov5_for_caltech/caltech-4/valid/labels.cache' images and labels... 161 found, 0 missing, 0 empty, 0 corrupt: 100% 161/161 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.61 anchors/target, 0.996 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
      "Plotting labels to runs/train/exp9/labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/train/exp9\u001b[0m\n",
      "Starting training for 350 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      0/349      34.1G     0.1204    0.02935          0        101        640: 100% 18/18 [00:12<00:00,  1.43it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0% 0/2 [00:00<?, ?it/s]WARNING ⚠️ NMS time limit 6.600s exceeded\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:09<00:00,  4.72s/it]\n",
      "                   all        161        328   8.39e-05     0.0122   4.28e-05   4.28e-06\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      1/349      40.3G     0.1185    0.02918          0        179        640:  39% 7/18 [00:03<00:05,  2.11it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 630, in <module>\n",
      "    main(opt)\n",
      "  File \"train.py\", line 524, in main\n",
      "    train(opt.hyp, opt, device, callbacks)\n",
      "  File \"train.py\", line 307, in train\n",
      "    loss, loss_items = compute_loss(pred, targets.to(device))  # loss scaled by batch_size\n",
      "  File \"/content/yolov5_for_caltech/utils/loss.py\", line 125, in __call__\n",
      "    tcls, tbox, indices, anchors = self.build_targets(p, targets)  # targets\n",
      "  File \"/content/yolov5_for_caltech/utils/loss.py\", line 195, in build_targets\n",
      "    device=self.device).float() * g  # offsets\n",
      "KeyboardInterrupt\n",
      "Error in atexit._run_exitfuncs:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/jax/_src/dispatch.py\", line 179, in wait_for_tokens\n",
      "    runtime_tokens.block_until_ready()\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/jax/_src/dispatch.py\", line 173, in block_until_ready\n",
      "    self.clear()\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/jax/_src/dispatch.py\", line 162, in clear\n",
      "    self.tokens = {}\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python train.py --data /content/yolov5_for_caltech/caltech-4/data.yaml --cfg yolov5l_eca.yaml --batch-size -1 --epochs 350"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### * This is the command for local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ../yolov5/train.py --data caltech-4/data.yaml --cfg ../yolov5/models/yolov5l_eca.yaml --batch-size -1 --epochs 350"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5 Train the yolov5l + SPD model for the dataset without augmentation.\n",
    "We stop the training manually after 1 epoch in this notebook. For more training log details, please see /before_dataAug/spd_b4.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### * This is the command for Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xaWcqfmsyq0p",
    "outputId": "6e3c2e73-7d54-48ad-d65c-72377d9337b9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=yolov5l_spd.yaml, data=/content/yolov5_for_caltech/caltech-4/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=350, batch_size=-1, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m⚠️ YOLOv5 is out of date by 29 commits. Use `git pull ultralytics master` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
      "YOLOv5 🚀 v6.2-240-g08889c1 Python-3.7.15 torch-1.13.0+cu117 CUDA:0 (A100-SXM4-40GB, 40536MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "2022-11-20 06:48:48.389104: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      7040  models.common.Focus                     [3, 64, 3]                    \n",
      "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 1]               \n",
      "  2                -1  1         0  models.common.space_to_depth            [1]                           \n",
      "  3                -1  3    206080  models.common.C3                        [512, 128, 3]                 \n",
      "  4                -1  1    295424  models.common.Conv                      [128, 256, 3, 1]              \n",
      "  5                -1  1         0  models.common.space_to_depth            [1]                           \n",
      "  6                -1  6   1314816  models.common.C3                        [1024, 256, 6]                \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 1]              \n",
      "  8                -1  1         0  models.common.space_to_depth            [1]                           \n",
      "  9                -1  9   7220224  models.common.C3                        [2048, 512, 9]                \n",
      " 10                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
      " 11                -1  1         0  models.common.space_to_depth            [1]                           \n",
      " 12                -1  3  13117440  models.common.C3                        [4096, 1024, 3]               \n",
      " 13                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
      " 14                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 9]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
      " 18                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 19                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 20           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 21                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
      " 22                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 23                -1  1         0  models.common.space_to_depth            [1]                           \n",
      " 24          [-1, 18]  1         0  models.common.Concat                    [1]                           \n",
      " 25                -1  3   2888704  models.common.C3                        [1280, 512, 3, False]         \n",
      " 26                -1  1   2360320  models.common.Conv                      [512, 512, 3, 1]              \n",
      " 27                -1  1         0  models.common.space_to_depth            [1]                           \n",
      " 28          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 29                -1  3  11544576  models.common.C3                        [2560, 1024, 3, False]        \n",
      " 30      [21, 25, 29]  1     32310  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n",
      "YOLOv5l_spd summary: 375 layers, 52282294 parameters, 52282294 gradients\n",
      "\n",
      "Transferred 75/613 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for --imgsz 640\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (A100-SXM4-40GB) 39.59G total, 0.68G reserved, 0.39G allocated, 38.51G free\n",
      "      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n",
      "    52282294       177.6         1.283         74.98         28.67        (1, 3, 640, 640)                    list\n",
      "    52282294       355.2         1.929          43.3         27.21        (2, 3, 640, 640)                    list\n",
      "    52282294       710.4         3.183          41.4         32.86        (4, 3, 640, 640)                    list\n",
      "    52282294        1421         5.792         46.62         45.83        (8, 3, 640, 640)                    list\n",
      "    52282294        2842        11.075         58.93         82.37       (16, 3, 640, 640)                    list\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 46 for CUDA:0 31.72G/39.59G (80%) ✅\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 101 weight(decay=0.0), 104 weight(decay=0.000359375), 104 bias\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/yolov5_for_caltech/caltech-4/train/labels.cache' images and labels... 1082 found, 0 missing, 4 empty, 0 corrupt: 100% 1082/1082 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/yolov5_for_caltech/caltech-4/valid/labels.cache' images and labels... 161 found, 0 missing, 0 empty, 0 corrupt: 100% 161/161 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.61 anchors/target, 0.996 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
      "Plotting labels to runs/train/exp7/labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/train/exp7\u001b[0m\n",
      "Starting training for 350 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      0/349      33.9G     0.1154       0.03          0         86        640: 100% 24/24 [00:16<00:00,  1.49it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:09<00:00,  4.98s/it]\n",
      "                   all        161        328          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      1/349      29.3G     0.1137     0.0293          0        103        640:  50% 12/24 [00:06<00:06,  1.99it/s]Exception in thread Thread-3:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/pin_memory.py\", line 49, in _pin_memory_loop\n",
      "    do_one_step()\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/pin_memory.py\", line 26, in do_one_step\n",
      "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 113, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch/multiprocessing/reductions.py\", line 305, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/usr/lib/python3.7/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/usr/lib/python3.7/multiprocessing/resource_sharer.py\", line 87, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 492, in Client\n",
      "    c = SocketClient(address)\n",
      "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 620, in SocketClient\n",
      "    s.connect(address)\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n",
      "\n",
      "      1/349      29.3G     0.1137     0.0293          0        103        640:  50% 12/24 [00:06<00:06,  1.88it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 630, in <module>\n",
      "    main(opt)\n",
      "  File \"train.py\", line 524, in main\n",
      "    train(opt.hyp, opt, device, callbacks)\n",
      "  File \"train.py\", line 314, in train\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\", line 488, in backward\n",
      "    self, gradient, retain_graph, create_graph, inputs=inputs\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\", line 199, in backward\n",
      "    allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python train.py --data /content/yolov5_for_caltech/caltech-4/data.yaml --cfg yolov5l_spd.yaml --batch-size -1 --epochs 350"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### * This is the command for local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ../yolov5/train.py --data caltech-4/data.yaml --cfg ../yolov5/models/yolov5l_spd.yaml --batch-size -1 --epochs 350"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 Train the original yolov5l model for the dataset with augmentation.\n",
    "We stop the training manually after 1 epoch in this notebook. For more training details, please see /after_dataAug/base_aft.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### * This is the command for Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hM9YFTJL0kW-",
    "outputId": "4c5fe06f-f908-4c85-86bb-236241fedc6c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=yolov5l.yaml, data=/content/yolov5_for_caltech/caltech-ped-2/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=350, batch_size=-1, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m⚠️ YOLOv5 is out of date by 29 commits. Use `git pull ultralytics master` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
      "YOLOv5 🚀 v6.2-240-g08889c1 Python-3.7.15 torch-1.13.0+cu117 CUDA:0 (A100-SXM4-40GB, 40536MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "2022-11-20 06:55:59.899876: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
      "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
      "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
      "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
      "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
      "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
      "  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
      " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
      " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
      " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
      " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
      " 24      [17, 20, 23]  1     32310  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n",
      "YOLOv5l summary: 368 layers, 46138294 parameters, 46138294 gradients, 108.2 GFLOPs\n",
      "\n",
      "Transferred 57/613 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for --imgsz 640\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (A100-SXM4-40GB) 39.59G total, 0.69G reserved, 0.35G allocated, 38.54G free\n",
      "      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n",
      "    46138294       108.2         1.137         77.65         27.71        (1, 3, 640, 640)                    list\n",
      "    46138294       216.5         1.609         44.12         24.34        (2, 3, 640, 640)                    list\n",
      "    46138294       432.9         2.554         40.88         25.22        (4, 3, 640, 640)                    list\n",
      "    46138294       865.8         4.551         48.23         31.34        (8, 3, 640, 640)                    list\n",
      "    46138294        1732         8.475         51.53          48.7       (16, 3, 640, 640)                    list\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 61 for CUDA:0 31.57G/39.59G (80%) ✅\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 101 weight(decay=0.0), 104 weight(decay=0.0004765625), 104 bias\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/yolov5_for_caltech/caltech-ped-2/train/labels' images and labels...3246 found, 0 missing, 185 empty, 0 corrupt: 100% 3246/3246 [00:00<00:00, 10931.34it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/yolov5_for_caltech/caltech-ped-2/train/labels.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/yolov5_for_caltech/caltech-ped-2/valid/labels' images and labels...311 found, 0 missing, 0 empty, 0 corrupt: 100% 311/311 [00:00<00:00, 4826.23it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/yolov5_for_caltech/caltech-ped-2/valid/labels.cache\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.53 anchors/target, 0.992 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
      "Plotting labels to runs/train/exp10/labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/train/exp10\u001b[0m\n",
      "Starting training for 350 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      0/349      34.1G     0.1182    0.03595          0         65        640: 100% 54/54 [00:28<00:00,  1.87it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:10<00:00,  3.63s/it]\n",
      "                   all        311        608    7.5e-05     0.0115   3.88e-05   8.21e-06\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      1/349      38.8G      0.111    0.03611          0        327        640:  43% 23/54 [00:10<00:14,  2.14it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 630, in <module>\n",
      "    main(opt)\n",
      "  File \"train.py\", line 524, in main\n",
      "    train(opt.hyp, opt, device, callbacks)\n",
      "  File \"train.py\", line 319, in train\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/utils/clip_grad.py\", line 43, in clip_grad_norm_\n",
      "    total_norm = torch.norm(torch.stack([torch.norm(g.detach(), norm_type).to(device) for g in grads]), norm_type)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/utils/clip_grad.py\", line 43, in <listcomp>\n",
      "    total_norm = torch.norm(torch.stack([torch.norm(g.detach(), norm_type).to(device) for g in grads]), norm_type)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch/functional.py\", line 1485, in norm\n",
      "    return _VF.norm(input, p, dim=_dim, keepdim=keepdim)  # type: ignore[attr-defined]\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python train.py --data /content/yolov5_for_caltech/caltech-ped-2/data.yaml --cfg yolov5l.yaml --batch-size -1 --epochs 350"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### * This is the command for local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ../yolov5/train.py --data caltech-ped-2/data.yaml --cfg ../yolov5/models/yolov5l.yaml --batch-size -1 --epochs 350"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2 Train the yolov5l + mobilenetv3 model for the dataset with augmentation.\n",
    "We stop the training manually after 1 epoch in this notebook. For more training details, please see /after_dataAug/mobile_aft.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### * This is the command for Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3PQxTwaH0oi7",
    "outputId": "9631ef67-6b1b-4103-c82b-594b4a074b3b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=yolov5l_mobilenetv3.yaml, data=/content/yolov5_for_caltech/caltech-ped-2/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=350, batch_size=-1, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m⚠️ YOLOv5 is out of date by 29 commits. Use `git pull ultralytics master` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
      "YOLOv5 🚀 v6.2-240-g08889c1 Python-3.7.15 torch-1.13.0+cu117 CUDA:0 (A100-SXM4-40GB, 40536MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "2022-11-20 06:57:54.424399: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
      "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
      "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
      "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
      "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
      "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
      "  9                -1  1         3  models.common.ECA                       [1024, 1024]                  \n",
      " 10                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
      " 11                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 12                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 13           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 14                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
      " 15                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 16                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 17           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 18                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
      " 19                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 20          [-1, 15]  1         0  models.common.Concat                    [1]                           \n",
      " 21                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
      " 22                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
      " 23          [-1, 11]  1         0  models.common.Concat                    [1]                           \n",
      " 24                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
      " 25      [18, 21, 24]  1     32310  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n",
      "YOLOv5l_mobilenetv3 summary: 372 layers, 46138297 parameters, 46138297 gradients, 108.2 GFLOPs\n",
      "\n",
      "Transferred 31/614 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for --imgsz 640\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (A100-SXM4-40GB) 39.59G total, 0.69G reserved, 0.35G allocated, 38.54G free\n",
      "      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n",
      "    46138297       108.2         1.139            77         27.22        (1, 3, 640, 640)                    list\n",
      "    46138297       216.5         1.609         43.92         23.99        (2, 3, 640, 640)                    list\n",
      "    46138297       432.9         2.556         39.27         27.17        (4, 3, 640, 640)                    list\n",
      "    46138297       865.8         4.559         47.78         31.31        (8, 3, 640, 640)                    list\n",
      "    46138297        1732         8.491         52.63         48.47       (16, 3, 640, 640)                    list\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 61 for CUDA:0 31.64G/39.59G (80%) ✅\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 101 weight(decay=0.0), 105 weight(decay=0.0004765625), 104 bias\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/yolov5_for_caltech/caltech-ped-2/train/labels.cache' images and labels... 3246 found, 0 missing, 185 empty, 0 corrupt: 100% 3246/3246 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/yolov5_for_caltech/caltech-ped-2/valid/labels.cache' images and labels... 311 found, 0 missing, 0 empty, 0 corrupt: 100% 311/311 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.53 anchors/target, 0.992 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
      "Plotting labels to runs/train/exp11/labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/train/exp11\u001b[0m\n",
      "Starting training for 350 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      0/349      34.1G     0.1186    0.03597          0         65        640: 100% 54/54 [00:29<00:00,  1.86it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:10<00:00,  3.45s/it]\n",
      "                   all        311        608   0.000139     0.0214   9.02e-05   2.05e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      1/349      38.9G     0.1125    0.03486          0        291        640:   9% 5/54 [00:02<00:24,  2.01it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 630, in <module>\n",
      "  File \"train.py\", line 524, in main\n",
      "    train(opt.hyp, opt, device, callbacks)\n",
      "  File \"train.py\", line 319, in train\n",
      "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0)  # clip gradients\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/utils/clip_grad.py\", line 43, in clip_grad_norm_\n",
      "    total_norm = torch.norm(torch.stack([torch.norm(g.detach(), norm_type).to(device) for g in grads]), norm_type)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/utils/clip_grad.py\", line 43, in <listcomp>\n",
      "    total_norm = torch.norm(torch.stack([torch.norm(g.detach(), norm_type).to(device) for g in grads]), norm_type)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch/functional.py\", line 1485, in norm\n",
      "    return _VF.norm(input, p, dim=_dim, keepdim=keepdim)  # type: ignore[attr-defined]\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python train.py --data /content/yolov5_for_caltech/caltech-ped-2/data.yaml --cfg yolov5l_mobilenetv3.yaml --batch-size -1 --epochs 350"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### * This is the command for local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ../yolov5/train.py --data caltech-ped-2/data.yaml --cfg ../yolov5/models/yolov5l_mobilenetv3.yaml --batch-size -1 --epochs 350"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3 Train the yolov5l + SE model for the dataset with augmentation.\n",
    "We stop the training manually after 1 epoch in this notebook. For more training details, please see /after_dataAug/se_aft.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### * This is the command for Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nOPdUl_S1Ene",
    "outputId": "ecd413d6-63ce-46ec-a561-723ced64bab3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=yolov5l_se.yaml, data=/content/yolov5_for_caltech/caltech-ped-2/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=350, batch_size=-1, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m⚠️ YOLOv5 is out of date by 29 commits. Use `git pull ultralytics master` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
      "YOLOv5 🚀 v6.2-240-g08889c1 Python-3.7.15 torch-1.13.0+cu117 CUDA:0 (A100-SXM4-40GB, 40536MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "2022-11-20 06:59:16.040188: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
      "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
      "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
      "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
      "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
      "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
      "  9                -1  1    131072  models.common.SE                        [1024, 1024]                  \n",
      " 10                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
      " 11                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 12                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 13           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 14                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
      " 15                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 16                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 17           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 18                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
      " 19                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 20          [-1, 15]  1         0  models.common.Concat                    [1]                           \n",
      " 21                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
      " 22                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
      " 23          [-1, 11]  1         0  models.common.Concat                    [1]                           \n",
      " 24                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
      " 25      [18, 21, 24]  1     32310  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n",
      "YOLOv5l_se summary: 374 layers, 46269366 parameters, 46269366 gradients, 108.3 GFLOPs\n",
      "\n",
      "Transferred 31/615 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for --imgsz 640\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (A100-SXM4-40GB) 39.59G total, 0.69G reserved, 0.35G allocated, 38.54G free\n",
      "      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n",
      "    46269366       108.2         1.141          76.2         28.97        (1, 3, 640, 640)                    list\n",
      "    46269366       216.5         1.611         44.44         23.33        (2, 3, 640, 640)                    list\n",
      "    46269366       432.9         2.554         41.64         26.25        (4, 3, 640, 640)                    list\n",
      "    46269366       865.8         4.557         49.21         31.69        (8, 3, 640, 640)                    list\n",
      "    46269366        1732         8.489         53.26         50.37       (16, 3, 640, 640)                    list\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 61 for CUDA:0 31.63G/39.59G (80%) ✅\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 101 weight(decay=0.0), 106 weight(decay=0.0004765625), 104 bias\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/yolov5_for_caltech/caltech-ped-2/train/labels.cache' images and labels... 3246 found, 0 missing, 185 empty, 0 corrupt: 100% 3246/3246 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/yolov5_for_caltech/caltech-ped-2/valid/labels.cache' images and labels... 311 found, 0 missing, 0 empty, 0 corrupt: 100% 311/311 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.53 anchors/target, 0.992 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
      "Plotting labels to runs/train/exp12/labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/train/exp12\u001b[0m\n",
      "Starting training for 350 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      0/349      34.2G     0.1185    0.03654          0         65        640: 100% 54/54 [00:29<00:00,  1.86it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:10<00:00,  3.42s/it]\n",
      "                   all        311        608   6.43e-05    0.00987   3.28e-05   6.02e-06\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      1/349      38.9G     0.1118    0.03534          0        291        640:   9% 5/54 [00:02<00:24,  2.01it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 630, in <module>\n",
      "    main(opt)\n",
      "  File \"train.py\", line 524, in main\n",
      "    train(opt.hyp, opt, device, callbacks)\n",
      "  File \"train.py\", line 314, in train\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\", line 488, in backward\n",
      "    self, gradient, retain_graph, create_graph, inputs=inputs\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\", line 199, in backward\n",
      "    allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python train.py --data /content/yolov5_for_caltech/caltech-ped-2/data.yaml --cfg yolov5l_se.yaml --batch-size -1 --epochs 350"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### * This is the command for local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ../yolov5/train.py --data caltech-ped-2/data.yaml --cfg ../yolov5/models/yolov5l_se.yaml --batch-size -1 --epochs 350"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.4 Train the yolov5l + ECA model for the dataset with augmentation.\n",
    "We stop the training manually after 1 epoch in this notebook. For more training details, please see /after_dataAug/eca_aft.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### * This is the command for Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pW9xNKh-1X1q",
    "outputId": "83b2395d-e559-4da2-87bf-9829b10a74fa",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=yolov5l_eca.yaml, data=/content/yolov5_for_caltech/caltech-ped-2/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=350, batch_size=-1, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m⚠️ YOLOv5 is out of date by 29 commits. Use `git pull ultralytics master` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
      "YOLOv5 🚀 v6.2-240-g08889c1 Python-3.7.15 torch-1.13.0+cu117 CUDA:0 (A100-SXM4-40GB, 40536MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "2022-11-20 07:00:27.772684: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
      "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
      "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
      "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
      "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
      "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
      "  9                -1  1         3  models.common.ECA                       [1024, 1024]                  \n",
      " 10                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
      " 11                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 12                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 13           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 14                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
      " 15                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 16                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 17           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 18                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
      " 19                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 20          [-1, 15]  1         0  models.common.Concat                    [1]                           \n",
      " 21                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
      " 22                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
      " 23          [-1, 11]  1         0  models.common.Concat                    [1]                           \n",
      " 24                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
      " 25      [18, 21, 24]  1     32310  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n",
      "YOLOv5l_eca summary: 372 layers, 46138297 parameters, 46138297 gradients, 108.2 GFLOPs\n",
      "\n",
      "Transferred 31/614 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for --imgsz 640\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (A100-SXM4-40GB) 39.59G total, 0.69G reserved, 0.35G allocated, 38.54G free\n",
      "      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n",
      "    46138297       108.2         1.139         77.71         27.37        (1, 3, 640, 640)                    list\n",
      "    46138297       216.5         1.609         48.13         23.64        (2, 3, 640, 640)                    list\n",
      "    46138297       432.9         2.556         40.68         25.77        (4, 3, 640, 640)                    list\n",
      "    46138297       865.8         4.559         48.38         30.89        (8, 3, 640, 640)                    list\n",
      "    46138297        1732         8.491         52.35         48.52       (16, 3, 640, 640)                    list\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 61 for CUDA:0 31.64G/39.59G (80%) ✅\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 101 weight(decay=0.0), 105 weight(decay=0.0004765625), 104 bias\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/yolov5_for_caltech/caltech-ped-2/train/labels.cache' images and labels... 3246 found, 0 missing, 185 empty, 0 corrupt: 100% 3246/3246 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/yolov5_for_caltech/caltech-ped-2/valid/labels.cache' images and labels... 311 found, 0 missing, 0 empty, 0 corrupt: 100% 311/311 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.53 anchors/target, 0.992 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
      "Plotting labels to runs/train/exp13/labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/train/exp13\u001b[0m\n",
      "Starting training for 350 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      0/349      34.1G     0.1186    0.03597          0         65        640: 100% 54/54 [00:28<00:00,  1.87it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:10<00:00,  3.40s/it]\n",
      "                   all        311        608   0.000139     0.0214   9.02e-05   2.05e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      1/349      38.9G     0.1125    0.03486          0        291        640:   9% 5/54 [00:02<00:26,  1.87it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 630, in <module>\n",
      "    main(opt)\n",
      "  File \"train.py\", line 524, in main\n",
      "    train(opt.hyp, opt, device, callbacks)\n",
      "  File \"train.py\", line 320, in train\n",
      "    scaler.step(optimizer)  # optimizer.step\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch/cuda/amp/grad_scaler.py\", line 341, in step\n",
      "    retval = self._maybe_opt_step(optimizer, optimizer_state, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch/cuda/amp/grad_scaler.py\", line 287, in _maybe_opt_step\n",
      "    if not sum(v.item() for v in optimizer_state[\"found_inf_per_device\"].values()):\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch/cuda/amp/grad_scaler.py\", line 287, in <genexpr>\n",
      "    if not sum(v.item() for v in optimizer_state[\"found_inf_per_device\"].values()):\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python train.py --data /content/yolov5_for_caltech/caltech-ped-2/data.yaml --cfg yolov5l_eca.yaml --batch-size -1 --epochs 350"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### * This is the command for local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ../yolov5/train.py --data caltech-ped-2/data.yaml --cfg ../yolov5/models/yolov5l_eca.yaml --batch-size -1 --epochs 350"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.5 Train the yolov5l + SPD model for the dataset with augmentation.\n",
    "We stop the training manually after 1 epoch in this notebook. For more training details, please see /after_dataAug/spd_aft.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### * This is the command for Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N-2Uzimi1fkZ",
    "outputId": "a8c31d5f-e0ff-4c3a-9c57-a479f4a688ef",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=yolov5l_spd.yaml, data=/content/yolov5_for_caltech/caltech-ped-2/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=350, batch_size=-1, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m⚠️ YOLOv5 is out of date by 29 commits. Use `git pull ultralytics master` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
      "YOLOv5 🚀 v6.2-240-g08889c1 Python-3.7.15 torch-1.13.0+cu117 CUDA:0 (A100-SXM4-40GB, 40536MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "2022-11-20 07:01:38.091610: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      7040  models.common.Focus                     [3, 64, 3]                    \n",
      "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 1]               \n",
      "  2                -1  1         0  models.common.space_to_depth            [1]                           \n",
      "  3                -1  3    206080  models.common.C3                        [512, 128, 3]                 \n",
      "  4                -1  1    295424  models.common.Conv                      [128, 256, 3, 1]              \n",
      "  5                -1  1         0  models.common.space_to_depth            [1]                           \n",
      "  6                -1  6   1314816  models.common.C3                        [1024, 256, 6]                \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 1]              \n",
      "  8                -1  1         0  models.common.space_to_depth            [1]                           \n",
      "  9                -1  9   7220224  models.common.C3                        [2048, 512, 9]                \n",
      " 10                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
      " 11                -1  1         0  models.common.space_to_depth            [1]                           \n",
      " 12                -1  3  13117440  models.common.C3                        [4096, 1024, 3]               \n",
      " 13                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
      " 14                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 9]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
      " 18                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 19                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 20           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 21                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
      " 22                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 23                -1  1         0  models.common.space_to_depth            [1]                           \n",
      " 24          [-1, 18]  1         0  models.common.Concat                    [1]                           \n",
      " 25                -1  3   2888704  models.common.C3                        [1280, 512, 3, False]         \n",
      " 26                -1  1   2360320  models.common.Conv                      [512, 512, 3, 1]              \n",
      " 27                -1  1         0  models.common.space_to_depth            [1]                           \n",
      " 28          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 29                -1  3  11544576  models.common.C3                        [2560, 1024, 3, False]        \n",
      " 30      [21, 25, 29]  1     32310  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n",
      "YOLOv5l_spd summary: 375 layers, 52282294 parameters, 52282294 gradients\n",
      "\n",
      "Transferred 75/613 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for --imgsz 640\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (A100-SXM4-40GB) 39.59G total, 0.68G reserved, 0.39G allocated, 38.51G free\n",
      "      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n",
      "    52282294       177.6         1.283         74.72         28.96        (1, 3, 640, 640)                    list\n",
      "    52282294       355.2         1.929         42.93         27.09        (2, 3, 640, 640)                    list\n",
      "    52282294       710.4         3.183          42.1          32.4        (4, 3, 640, 640)                    list\n",
      "    52282294        1421         5.792         46.49         46.04        (8, 3, 640, 640)                    list\n",
      "    52282294        2842        11.075         58.76         82.59       (16, 3, 640, 640)                    list\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 46 for CUDA:0 31.72G/39.59G (80%) ✅\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 101 weight(decay=0.0), 104 weight(decay=0.000359375), 104 bias\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/yolov5_for_caltech/caltech-ped-2/train/labels.cache' images and labels... 3246 found, 0 missing, 185 empty, 0 corrupt: 100% 3246/3246 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/yolov5_for_caltech/caltech-ped-2/valid/labels.cache' images and labels... 311 found, 0 missing, 0 empty, 0 corrupt: 100% 311/311 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.53 anchors/target, 0.992 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
      "Plotting labels to runs/train/exp14/labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/train/exp14\u001b[0m\n",
      "Starting training for 350 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      0/349      33.9G     0.1166     0.0375          0         92        640: 100% 71/71 [00:40<00:00,  1.76it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:11<00:00,  2.87s/it]\n",
      "                   all        311        608   6.43e-05    0.00987   3.25e-05   5.41e-06\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      1/349        39G     0.1122    0.03643          0        185        640:  13% 9/71 [00:04<00:33,  1.84it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 630, in <module>\n",
      "    main(opt)\n",
      "  File \"train.py\", line 524, in main\n",
      "    train(opt.hyp, opt, device, callbacks)\n",
      "  File \"train.py\", line 307, in train\n",
      "    loss, loss_items = compute_loss(pred, targets.to(device))  # loss scaled by batch_size\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python train.py --data /content/yolov5_for_caltech/caltech-ped-2/data.yaml --cfg yolov5l_spd.yaml --batch-size -1 --epochs 350"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### * This is the command for local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ../yolov5/train.py --data caltech-ped-2/data.yaml --cfg ../yolov5/models/yolov5l_spd.yaml --batch-size -1 --epochs 350"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9 Copy result to Google drive\n",
    "If you do not need to copy result to google drive, just ignore this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "la-1lQZWyskB"
   },
   "outputs": [],
   "source": [
    "%cp -r /content/yolov5/runs/train/exp /content/gdrive/MyDrive"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
